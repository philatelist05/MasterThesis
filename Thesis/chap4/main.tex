\chapter{Experimental Evaluation}\label{chap:experimental_evaluation}
In this chapter we describe our approach to evaluate the performance of crowdsourced ontology validation steps. More precisely, in \hyperref[sec:evaluation_metrics]{Section~\ref*{sec:evaluation_metrics}} we start by describing all relevant performance metrics used to quantify the improvements. Then, in \hyperref[sec:evaluation_datasets]{Section~\ref*{sec:evaluation_datasets}} an overview of the used datasets~(e.g. ontologies) is given and finally, \hyperref[sec:crowdsourcing_task_interfaces]{Section~\ref*{sec:crowdsourcing_task_interfaces}} shows various interfaces which were presented to contributors to facilitate crowdsourcing task completion.

\subsubsection{Evaluation Hypothesis}
Based on existing efforts for ontology validation using crowdsourcing~(see \hyperref[sec:ucomp_protege_plugin]{Section~\ref*{sec:ucomp_protege_plugin}}), we formulate the following evaluation hypothesis:
\begin{quotation}
	The crowd performs ontology validation steps better if context is added to crowdsourcing tasks.
\end{quotation}

To evaluate the hypothesis stated above, we performed experimental evaluations on the implemented Protege~plugin. \hyperref[table:overview_exp_evaluation]{Table~\ref*{table:overview_exp_evaluation}} gives an overview of the experiments including their settings and used datasets, described thoroughly in the next sections. 
\begingroup
\renewcommand{\arraystretch}{1.5}
\begin{table}
	\begin{tabularx}{\textwidth}{l c *{4}{Y}}
		\toprule
		\multirow{2}{*}{\emph{Methods}} & \multicolumn{2}{c}{\emph{Data}} & \multicolumn{3}{c}{\emph{Crowdsourcing Settings}}\\
		\cmidrule(lr){2-3} \cmidrule(lr){4-6} 
		 & Ontology & No. of Classes & Judgements/ Price & Worker Selection & Quality Control\\
		\midrule
		 None, EC, NN, ES & Climate & 101 & $5/0.05$ & Level 3, AUS, UK, USA & Quiz\\
		 None, EC, NN, ES & Tennis & 52 & $5/0.05$ & Level 3, AUS, UK, USA & Quiz\\
		 None, EC, NN, ES & Finance & 77 & $5/0.05$ & Level 3, AUS, UK, USA & Quiz\\
		 \bottomrule
	\end{tabularx}
	\caption{Overview of performed ontology validation tasks, including datasets and settings.~~~~~~~\texttt{EC=Embedded Context, NN=Neighbouring Nodes, ES=External Source}}
	\label{table:overview_exp_evaluation}
\end{table}
\endgroup

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% SECTION: EVALUATION METRICS %
\input{section_evaluationMetrics.tex}

% SECTION: DATASETS %
\input{section_datasets.tex}

% SECTION: CROWDSOURCING TASK INTERFACES %
\input{section_taskInterfaces.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

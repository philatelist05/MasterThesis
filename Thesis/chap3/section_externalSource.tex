\section{External Source}\label{sec:external_source}
An alternative method of context enrichment is based on fetching concept definitions from external sources, especially when these are not already available as metadata annotations in the ontologies that are validated. The lookup is solely based on the concept's name, neglecting the connected nature of an ontology. Dictionaries have always been the first choice when it comes to searching for specific information about words or phrases.

This section begins with an introduction in the theory of dictionaries, discusses searching problems and strategies to overcome these and briefly describes several online dictionaries including the one we used in our approach.

\paragraph{Online Dictionary Examples} We have chosen some well-known, freely accessible online dictionaries that were used in various research
fields.

%WordNet
Started as a research project in 1985 at Princeton University \textbf{WordNet}~\cite{fellbaum1998} is best characterised as a dictionary browser rather than just an online dictionary. It allows users to explore its contents on the basis of semantic, rather than alphabetic similarities. Users look up information along more than one path, semantics being among them. How one wants to explore the possibilities of online dictionaries rather depends on one's ideas and applications one has in mind. 

The building blocks of WordNet are \textit{synsets} which are defined as sets of words having similar semantics~(synonymy). It is important that synonymy does not entail unrestricted interchangeability. By that criterion natural languages would have very few synonyms. Instead, synonymy is typically relative to a context which is encoded as links between and within synsets. 
Several linguistic relations are defined in WordNet, for example \textit{polysemy/monosemy}, \textit{hyponymy/hypernymy} and \textit{meronymy/holonymy}. 
Polysemy/Monosemy describes the fact that a word may have multiple meanings or one meaning. Hyponymy/Hypernymy means that words or phrases are included in the meaning of another word. Meronymy/Holonymy describes part-of or member-of relationships.

The WordNet architecture~\cite{fellbaum1998} as illustrated in~\hyperref[fig:wordnet_architecture]{Figure~\ref*{fig:wordnet_architecture}} can be split into these parts:
\begin{enumerate}
		\item Lexical Source Files
		\item the Grinder
		\item the Lexical Database
		\item Software Tools and Interfaces
\end{enumerate}

\begin{figure}
	 \centering
	 \includegraphics[width=0.5\textwidth]{drawio/WordNet_Architecture}
	 \caption{The architecture of the WordNet System~\cite{fellbaum1998}}\label{fig:wordnet_architecture}
\end{figure}


The \textit{Lexical Database} forms the heart of the WordNet system. It is the result of processing all lexical source files. There are many tools available, written in various programming languages like Perl or awk, to interact with the database. 

WordNet offers some \textit{interfaces} to users for interaction. Depending on the area of application there are textual interfaces~(Command Line Interfaces and APIs) and graphical interfaces~(Desktop Software and Web Applications). Invoking the search form and starting search tasks can also be done via browser interface\footnote{\url{http://wordnetweb.princeton.edu/perl/webwn} accessed 2018/06/14}.

WordNet's key success factor is its potentials in terms of Natural Language Processing~(NLP). It was also used as information source in many other fields~\cite{morato2004}, these are: Image Retrieval, Information Retrieval, Document Classification, Query Expansion, Machine Translation and Conceptual Disambiguation.

%TODO: Make section for wordnik here%
\label{sec:wordnik}
A different approach was taken by \textbf{WordNik}\footnote{\url{https://www.wordnik.com/} accessed 2018/06/15}. It targets native English speakers who look up words that are rare~(technical terms or dialect terms), very old or very new. They often search for definitional information which is incomplete or missing in traditional dictionaries. Users tolerate published imperfection because they opt for relevant, actual and cutting-edge information, even though not officially approved by editors~\cite{burnett1979}. They want to understand the context of word usage in sentences, not necessarily explanatory statements as in printed or even online dictionaries.

The driving force behind WordNik was contribution. It processes and aggregates external user-generated content such as tweets, newspaper articles, scientific articles or uploaded Flickr\footnote{\url{https://www.flickr.com/} accessed 2018/06/15} images. This is similar to what search engines do, but with restricted scope. The creators of WordNik observed that very few people write word definitions, they rather add meta linguistic information such as lists of their favourite words, comments or tags. WordNik additionally collects statistics about lexicographical terms, more or less frequently searched words and most commented words. 

WordNik also offers an API for programmatically accessing their resources\footnote{\url{https://developer.wordnik.com/} accessed 2018/06/15}. At the time of writing this thesis free access is granted for non-profit, non-commercial use with a limitation on the number of API calls. 
After a successful registration process, an API token is provided which is a prerequisite for API interaction. Besides Web access, a handful of libraries\footnote{\url{https://developer.wordnik.com/libraries} accessed 2018/06/15}, available in many programming languages, were created to facilitate integration with third-party applications. 

\textbf{Wiktionary}\footnote{\url{https://www.wiktionary.org/} accessed 2018/06/15} is a freely accessible, collaborative online lexicon~\cite{granger2012}. Whereas traditional dictionaries are the product of a small group of expert lexicographers, collaboratively constructed dictionaries are created by many, not necessarily expert users. This has the advantage that new lexical entries are added more frequently and existing ones are continuously updated. Users are encouraged to participate in content creation and maintenance. New lexical entries are discussed in the community until a consensus is reached. 

An important goal of Wiktionary is openness towards multilingualism. It was first launched in 2002 and indented as an "add-on" to Wikipedia\footnote{\url{https://www.wikipedia.org/} accessed 2018/06/16}. At that time it was only available in English, but now translations exist for nearly every spoken language. However, they differ in scope and community size. Each Wiktionary is accessible by prepending the respective ISO~639~language~code\footnote{\url{https://www.iso.org/iso-639-language-codes.html} accessed 2018/06/16} to the common wiktionary domain.

Content is organised as collections of pages, each containing a title and a body. There are four page categories:
\begin{inparaenum}[1)]
		\item Article Pages,
		\item Redirect Pages,
		\item Talk Pages and
		\item Internal Pages
\end{inparaenum}.
Most pages are \emph{Article Pages}, containing the actual linguistic information. With \emph{Redirect Pages}, users are able to navigate from page to page. At page creation, \emph{Talk Pages} help editors in collecting ideas, expressing criticism, asking questions and discussing page contents. \emph{Internal Pages} are protected and contain motivational information, goals, statistics, indices, appendices and guidelines for contributors. 

Wiktionary is not targeted to specific groups of people nor its content serves a specific purpose, instead, it is open for everyone. 
Linguistic knowledge is organised in separate sections as explained in the next paragraphs: 

It may sound surprising that each page starts with the \emph{language} of the term or phrase because each page belongs to a specific translation of Wiktionary anyway. However, this is necessary because the same term can be encoded in multiple languages. For example, the term \texttt{boat} is used in five languages\footnote{\url{https://en.wiktionary.org/wiki/boat} accessed 2018/06/16}. 

The \textit{etymology} section describes origin and history of a word. It helps linguists in exploring linguistic relations such as synonymy/antonymy, hypernymy/hyponymy and homonymy/polysemy. They are also interested, whether and how the meaning has changed over time. 

\textit{Phonetic references} are appreciated not only by language learners but also by readers who are unfamiliar with particular terms. The term's pronunciation is encoded using audio samples or phonetic notations. 

In contrast to other dictionaries which focus on canonical word forms, Wiktionary also contains entries for inflected word forms. For example, the English verb \texttt{go} and its \textit{morphology} \texttt{went} are encoded as separate entries. Additionally, it may include the declension of an adjective or the conjunction of a verb.

Each term is associated with a \textit{syntactic category} which includes part of speech tags for single words, idioms, proverbs and multi-word expressions. Apart from these, there are also other tags available. For example, nouns are marked as countable/uncountable or singular/plural. 

The most interesting part for dictionary readers is probably the section \textit{semantic knowledge} which describes the meaning of a term. It includes example sentences, quotations, links to other terms, glosses and linguistic labels. The gloss of a word is either a marginal or interlinear notation of the word's meaning. Non-linguists are eventually more familiar with the term \emph{glossary} which denotes to collections of glosses. 

\textit{Cross-lingual knowledge} is especially important for translators and educators who are interested in multilingual realtions. This is expressed as links between pages of differing language. For example, descriptions of the English word \texttt{boat} are contained in a page with links to \texttt{water~craft}, \texttt{full-house} and conformation to \texttt{cyclohexane}.

A valuable feature for non-native speakers is \emph{graphical knowledge}. It is obvious that humans grasp the meaning of a term faster by just looking at a picture or photograph than reading through long textual descriptions. Unfortunately, not all terms can be expressed in pictures or photographs though. 

From a technical perspective Wiktionary is based on MediaWiki\footnote{\url{https://www.mediawiki.org/wiki/MediaWiki} accessed 2018/06/17}, a free and open source software written in PHP\footnote{\url{http://www.php.net/} accessed 2018/06/17}. The software is distributed under the GNU~General~Public~License~(GPL) and maintained by the WikiMedia~Foundation\footnote{\url{https://wikimediafoundation.org/wiki/Home} accessed 2018/06/17}, a non-profit organisation aimed at supporting free, multilingual, educational content. MediaWiki is also used by many other wikis\footnote{\url{https://wikistats.wmflabs.org/} accessed 2018/06/17}.

The majority of wiki features are accessible via public API. Clients can request features or send commands over the \textit{MediaWiki~Action~API}\footnote{\url{https://www.mediawiki.org/wiki/API:Main_page} accessed 2018/06/17}. It has querying, searching, parsing and manipulation capabilities.

\subsection{Dictionary based Approach}\label{sec:enrichment_dictionary_approach}
Intuitively, the idea of generating descriptions using dictionary lookups is simple: starting from a concept name, descriptions are built from consulting an online dictionary. 

A schematic overview of the overall workflow is shown in~\hyperref[fig:external_source_workflow]{Figure~\ref*{fig:external_source_workflow}}.
\begin{figure}
	 \centering
	 \includegraphics[width=0.9\textwidth]{drawio/External_Source_Workflow}
	 \caption{Conceptual workflow of WordNik consultation to generate concept descriptions}\label{fig:external_source_workflow}
\end{figure}
The idea is to use the concept name as a baseline for any further processing. Often, the name can not be used directly as input to WordNik because it contains unwanted characters such as excessive spaces, quotes, dots or just non-printable characters. This is especially true for learned ontologies, generated from textual sources. Our algorithm uses the built-in text manipulation capabilities of the JDK to pre-process concept names. Among the other approaches introduced earlier in this section, it is yet simple but still provides good results. 

Next, WordNik is consulted to find example sentences for normalised concept names. In contrast to traditional dictionaries, WordNik searches in all kinds of available online content, including newspapers, journals, scientific publications, tweets and others. 
All API interaction is protected against unauthorised access, however, to help developers learning the API, some features are available in isolated Sandbox~Mode\footnote{\url{https://developer.wordnik.com/docs} accessed  2018/06/21}. For instance, example sentences for the word \texttt{bird} can be fetched from the URL \texttt{/word.json/bird/examples}.

Depending on wether a single concept or multiple concepts are validated, example sentences need to be harmonised, which is realised by storing intermediate results and mapping these to the initial concepts. 

To conclude, this approach is rather simple and easy to implement, however, it may have the potential to generate wrong results, especially for ambiguous concept names. 

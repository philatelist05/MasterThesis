\begin{kurzfassung}
	Ein wichtiger Bestandteil des Semantik Web Lebenszyklus ist die Überprüfung der Ontologie Relevanz. Dies ist insbesondere der Fall bei erlernten 
	Ontologien, welche von Natur aus Fehler enthalten. Obwohl viele davon von Algorithmen gelöst werden können, ist dies mitunter bei
	komplexen Problemstellungen schwierig. Crowdsourcing stellt eine kosteneffiziente Alternative dar die diese Problemstellungen mit menschlicher
	Kraft löst. Dennoch ist die Performance jener Ansätze die Crowdsourcing mit Ontologie Validierung verknüpft wenig zufriedenstellend. 
	
	Ein vielversprechender Ansatz dieses Problem zu lösen wäre, wenn Crowdsourcing Aufgaben zusätzliche Informationen zur besseren
	Verständlichkeit enthielten. Dieser Kontext hätte nicht nur einen positiven Einfluss auf die Performance der Teilnehmer, sondern würde auch 
	zur besseren Qualität der Ergebnisse beitragen.
	
	Obwohl gewisse Fortschritte in diesem Bereich erst kürzlich erzielt wurden, befasste sich keine der Publikationen mit dem Thema Kontext
	im Zusammenhang mit Crowdsourcing. In dieser Diplomarbeit präsentieren wir 3 neuartige Methoden die Kontext für Crowdsourcing Aufgaben herstellen 
	um die Relevanz von Konzepten für eine bestimmte Domäne zu überprüfen. Während die auf Ontologien basierende Methode hierarchische Relationen
	verarbeitet, generiert die auf Metadaten basierende Methode Beschreibungen welche auf Annotationen beruhen. Durch Suchabfrage über die Platform
	WordNik	werden Beispielsätze geformt, welche die Basis für die dritte Methode bilden. 
	
	Zur Auswertung der Ergebnisse integrierten wir alle 3 Methoden in das bestehende uComp Protege Plugin, welches die Eingliederung von Crowdsourcing 
	Aufgaben zur Validierung von Ontologien innerhalb des Ontologie Editors Protege ermöglicht. Die Methoden wurden an 3 Ontologien der Bereiche
	Klimawandel, Tennis und Finanzen getestet. Die Metriken Precision, Recall und F-Measure wurden für jeden Datensatz berechnet um Rückschlüsse über 
	die Performance der getesteten Methoden ziehen zu können. Die Auswertungen ergaben, dass die auf Metadaten basierende Methode die besten
	Ergebnisse lieferte. Die anderen Methoden hatten Probleme in bestimmten Situationen, beispielsweise konnte die Verzeichnis basierende Methode 
	bei mehrdeutigen Konzepten nicht überzeugen. Weiters hatte die Ontologie basierende Methode Schwierigkeiten bei Ontologien welche nur aus wenigen
	Subklassen Beziehungen bestanden. Alles in allem lieferten alle 3 Methoden Ergebnisse von höchster Qualität wodurch die Performance der Teilnehmer
	durch das Hinzufügen von kontextbezogener Information gesteigert werden konnte. 
	
\end{kurzfassung}
\begin{kurzfassung}
	%Ein wichtiger Bestandteil des Semantik Web Lebenszyklus ist die Überprüfung der Ontologie Relevanz. Dies ist insbesondere der Fall bei erlernten 
	%Ontologien, welche von Natur aus Fehler enthalten. Obwohl viele davon von Algorithmen gelöst werden können, ist dies mitunter bei
	%komplexen Problemstellungen schwierig. Crowdsourcing stellt eine kosteneffiziente Alternative dar die diese Problemstellungen mit menschlicher
	%Kraft löst. Dennoch ist die Performance jener Ansätze die Crowdsourcing mit Ontologie Validierung verknüpft wenig zufriedenstellend. 
	%
	%Ein vielversprechender Ansatz dieses Problem zu lösen wäre, wenn Crowdsourcing Aufgaben zusätzlich kontextbezogene Informationen zur besseren
	%Verständlichkeit enthielten. Dieser Kontext hätte nicht nur einen positiven Einfluss auf die Performance der Teilnehmer, sondern würde auch 
	%zur besseren Qualität der Ergebnisse beitragen.
	%
	%Obwohl gewisse Fortschritte in diesem Bereich erst kürzlich erzielt wurden, befasste sich keine der Publikationen mit dem Thema Kontext
	%im Zusammenhang mit Crowdsourcing. In dieser Diplomarbeit präsentieren wir 3 neuartige Methoden die Kontext für Crowdsourcing Aufgaben herstellen 
	%um die Relevanz von Konzepten für eine bestimmte Domäne zu überprüfen. Während die auf Ontologien basierende Methode hierarchische Relationen
	%verarbeitet, generiert die auf Metadaten basierende Methode Beschreibungen welche auf Annotationen beruhen. Durch Suchabfrage über die Platform
	%WordNik	werden Beispielsätze geformt, welche die Basis für die dritte Methode bilden. 
	%
	%Zur Auswertung der Ergebnisse integrierten wir alle 3 Methoden in das bestehende uComp Protege Plugin, welches die Eingliederung von Crowdsourcing 
	%Aufgaben zur Validierung von Ontologien innerhalb des Ontologie Editors Protege ermöglicht. Die Methoden wurden an 3 Ontologien der Bereiche
	%Klimawandel, Tennis und Finanzen getestet. Die Metriken Precision, Recall und F-Measure wurden für jeden Datensatz berechnet um Rückschlüsse über 
	%die Performance der getesteten Methoden ziehen zu können. Die Auswertungen ergaben, dass die auf Metadaten basierende Methode die besten
	%Ergebnisse lieferte. Die anderen Methoden hatten Probleme in bestimmten Situationen, beispielsweise konnte die Verzeichnis basierende Methode 
	%bei mehrdeutigen Konzepten nicht überzeugen. Weiters hatte die Ontologie basierende Methode Schwierigkeiten bei Ontologien welche nur aus wenigen
	%Subklassen Beziehungen bestanden. Alle 3 Methoden lieferten Ergebnisse von höchster Qualität (F-Measure größer 80\%) wodurch die
	%Performance der Teilnehmer durch das Hinzufügen von kontextbezogener Information gesteigert werden konnte. 
	
	Ein wichtiger Teil des Semantik Web Lebenszyklus ist die Ontologie Validierung,
	insbesondere bei erlernten Ontologien, die von Natur aus Fehler enthalten.
	Obwohl mittlerweile viele dieser Fehler von Algorithmen erkannt werden,
	ist dies mitunter bei komplexen Problemstellungen schwierig. Crowdsourcing stellt eine
	kosteneffiziente Alternative dar, die diese Aufgaben an eine Gruppe freiwilliger User (Crowd)
	auslagert. Dennoch gibt es bei der Ontologie Validierung mittels Crowdsourcing Verbesserungsbedarf.

	Ein Lösungsansatz wäre die Zugabe kontextbezogener Informationen zu Crowdsourcing Aufgaben.
	Dies hätte mitunter einen positiven Einfluss auf das Validierungsergebnis.

	Obwohl Fortschritte in diesem Bereich erzielt wurden, gibt es noch wenig Literatur
	zu diesem Thema. In dieser Diplomarbeit stellen wir 3 Methoden vor, die Kontext 
	generieren um die Relevanz von Konzepten innerhalb einer
	Domäne zu überprüfen. Während der Ontology-based-Approach hierarchische
	Relationen verarbeitet, basiert der Metadata-based-Approach auf Annotationen.
	Als Basis für die letzte Methode (Dictionary-based-Approach) dienen Beispielsätze des Online
	Wörterbuchs WordNik.

	Alle 3 Methoden wurden als Erweiterung des uComp Protege Plugin konzipiert, 
	ein Plugin für den Ontologie Editor Protege, das die Validierung von Ontologien mittels Crowdsourcing
	ermöglicht. Im Rahmen von 3 Experimenten mit Datensätzen aus den Bereichen Klimawandel, Tennis und Finanzen
	wurden alle 3 Methoden getestet. Die Metriken Precision, Recall und F-Measure wurden für jeden Datensatz berechnet
	um Rückschlüsse über die Performance der getesteten Methoden ziehen zu können. Der Metadata-based-Approach
	lieferte die besten Validierungsergebnisse. Anhand der guten bis sehr guten Ergebnisse aller 3 Methoden (F-Measure
	größer 80\%) wurde gezeigt, dass die Qualität der Validierung durch das Hinzufügen kontextbezogener Information
	gesteigert werden konnte.

\end{kurzfassung}
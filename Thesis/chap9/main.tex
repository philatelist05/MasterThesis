\chapter{Summary \& Future Work}\label{chap:summary_and_future_work}


%SUMMARY%
%1.st paragraph: briefly describe the motivation and approach									DONE
%2.nd paragraph: briefly describe proposed methods												DONE
%3.rd paragraph: briefly describe the results													DONE

%FUTURE WORK%
%4.th ff paragraphs: describe big pricture														DONE
	% Proposed solution is embedded into bigger context (e.g. ontology learning solution)		DONE
	% Provides only a tiny poprtion																DONE

%paragraph: add transition text to open questions --- future tasks								DONE
%paragraph: for each open task add a new paragraph here

In this thesis we investigated whether contextual information in Crowdsourcing tasks helped to achieve better results for performing ontology validation using Crowdsourcing techniques. Crowdsourcing is a technique of distributing small tasks to a typically large group of human workers. It offers a cost effective method of solving tasks which are traditionally hard for machines but easily solvable by humans. Contextual information is any kind of of additional information that is supplied with a crowdsourcing task that improves the understanding of the task goals.

We presented three novel methods that enrich Crowdsourcing tasks with contextual information to validate the relevance of concepts for a particular domain of interest. Whereas the Ontology~based~Approach processes hierarchical relations, the Metadata~based~Approach generates descriptions based on annotations that were encoded within the ontology, the idea of the Dictionary~based~Approach is to form the explanations from example sentences by conducting the online dictionary \hyperref[sec:wordnik]{WordNik}.

All three approaches that were evaluated on three ontologies covering the domains of climate change, tennis and finance worked better than providing no Context at all. The Metadata~based~Approach outperformed all other methods in terms of precision and recall, leaving little room for future improvements. The other two approaches had some difficulties in certain situations, for example the Dictionary~based~Approach sometimes added inappropriate explanations, especially for concepts with multiple meanings associated. Likewise, the Ontology~based~Approach is limited to highly connected ontologies containing many subsumption relations. 

Before discussing open questions that needs investigation in future work, we take a look at the beginnings of this thesis. We explain, how our contributions relate to the overarching vision of providing an ontology learning solution which beats current implementations. 

It started by the publication~\cite{liu2005semi} which described the initial ontology learning framework. It generates the target ontology by conducting various sources and continuously extending a seed ontology. The framework underwent multiple revisions~\cite{weichselbraun2010_a, weichselbraun2010_b} until validation capabilities using Crowdsourcing techniques were integrated into the framework~\cite{wohlgenannt2012}.  
At that time human evaluation of learned ontologies was just at the beginning, leaving much room for improvements. 

Then the question arises, how the results of this thesis can contribute to this vision. This unexplored topic needs to be addressed by future research, possibly only after the improvement suggestions that are related to the approach taken by this thesis are in place. 

While this work tried to advance research, covering the intersection between Semantic Web technologies and Crowdsourcing, there are still several open questions that could not be addressed, because these new questions that are discussed in the remainder of this chapter arose during the course of this work.

